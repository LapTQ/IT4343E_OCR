{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_captioning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LapTQ/image_captioning/blob/main/image_captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hungpham13/Vietnamese-HTR.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ_6PnrTXw-c",
        "outputId": "853beb38-8423-49a7-a629-1512a4ad1fda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Vietnamese-HTR'...\n",
            "remote: Enumerating objects: 2403, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 2403 (delta 0), reused 4 (delta 0), pack-reused 2399\u001b[K\n",
            "Receiving objects: 100% (2403/2403), 427.59 MiB | 10.63 MiB/s, done.\n",
            "Checking out files: 100% (2395/2395), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rQiOo4_Fd7lh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/0825_DataSamples 1/labels.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgkwHIEfYniD",
        "outputId": "d4a393cd-7acd-4eca-b600-32baf7604fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"1.jpg\": \"Số 3 Nguyễn Ngọc Vũ, Hà Nội\",\n",
            "    \"2.jpg\": \"Số 30 Nguyên Hồng, Láng Hạ, Đống Đa, Hà Nội\",\n",
            "    \"3.jpg\": \"58 Thái Thịnh, Đống Đa, Hà Nội\",\n",
            "    \"4.jpeg\": \"Số 370/8 khu phố 5B, phường Tân Biên, Biên Hòa, Đồng Nai\",\n",
            "    \"5.jpg\": \"Vĩnh Trung Plaza, B, 255-257 đường Hùng Vương, phường Vĩnh Trung\",\n",
            "    \"6.jpg\": \"Tòa nhà 34T, Hoàng Đạo Thúy, Hà Nội\",\n",
            "    \"7.jpg\": \"40 Cát Linh, Đống Đa, Hà Nội\",\n",
            "    \"8.jpg\": \"phòng 101, tầng 1, lô 04-TT5B, khu đô thị Tây Nam Linh Đàm\",\n",
            "    \"9.JPG\": \"Nhà 87 ngõ 416 Đê La Thành\",\n",
            "    \"10.JPG\": \"Up coworking Space, 89 Láng Hạ, Hà Nội\",\n",
            "    \"11.jpg\": \"192 Ngô Đức Kế, quận 1, Hồ Chí Minh\",\n",
            "    \"12.jpg\": \"số 5 Công Trường Mê Linh, phường Bến Nghé, quận 1\",\n",
            "    \"13.jpg\": \"90A đường Mai Xuân Thưởng, tỉnh Gia Lai\",\n",
            "    \"14.jpg\": \"96/7/12B Phạm Văn Đồng, thành phố Pleiku\",\n",
            "    \"15.jpg\": \"168 Ngô Gia Tự, thành phố Hà Tĩnh\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/0916_Data Samples 2'\n",
        "test_img_dir = '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/1015_Private Test'\n",
        "\n",
        "image_height, image_width = 120, 1900\n",
        "vocab_size = 10000\n",
        "\n",
        "# Fixed length allowed for any sequence\n",
        "seq_length = 25\n",
        "\n",
        "# Dimension for the image embeddings and token embeddings\n",
        "embedding_dim = 512\n",
        "\n",
        "# Per-layer units in the feed-forward network\n",
        "units = 512\n",
        "\n",
        "batch_size = 4\n",
        "epochs = 30\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "mjm7Y-lYdZYT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of training images:', len(list(Path(train_img_dir).glob('*.png'))))\n",
        "print('Number of testing images:', len(list(Path(test_img_dir).glob('*.png'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU8HNz-regz_",
        "outputId": "5e16d30d-f634-4797-ddff-6887af3a4144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 1823\n",
            "Number of testing images: 549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train_json = json.load(\n",
        "    open(train_img_dir + '/labels.json', 'r')\n",
        ")\n",
        "\n",
        "test_json = json.load(\n",
        "    open(test_img_dir + '/labels.json', 'r')\n",
        ")\n",
        "\n",
        "train_data = {os.path.join(train_img_dir, image_name): '<start> ' + label + ' <end>' for image_name, label in train_json.items()}\n",
        "test_data = {os.path.join(test_img_dir, image_name): '<start> ' + label + ' <end>' for image_name, label in test_json.items()}"
      ],
      "metadata": {
        "id": "pQGy_mYAayjJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_and_resize(img_path):\n",
        "    img_string = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img_string)\n",
        "\n",
        "    # resize to desired shape\n",
        "    # input is of int [0, 255], but output is of float [0, 255]\n",
        "    img = tf.image.resize_with_pad(img, image_height, image_width)\n",
        "\n",
        "    # invert color      ##############################\n",
        "    img = 255 - img\n",
        "\n",
        "    # preprocess_input accept input of type float [0, 255]\n",
        "    img = keras.applications.densenet.preprocess_input(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
        "strip_chars = strip_chars.replace('<', '')\n",
        "strip_chars = strip_chars.replace('>', '')\n",
        "strip_chars = strip_chars.replace('/', '')\n",
        "strip_chars = strip_chars.replace('-', '')\n",
        "\n",
        "vectorization = keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_length,\n",
        "    standardize=lambda label: tf.strings.regex_replace(label, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        ")\n",
        "\n",
        "vectorization.adapt(list(train_data.values()))\n",
        "\n",
        "def preprocess_input(img_path, label):\n",
        "    return decode_and_resize(img_path), vectorization(label)\n",
        "\n",
        "def make_dataset(img_paths, labels, training):\n",
        "    assert training is True or training is False\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, labels))\n",
        "    dataset = dataset.map(preprocess_input, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.prefetch(buffer_size=2000)\n",
        "    # dataset = dataset.cache()\n",
        "    if training: \n",
        "        dataset = dataset.shuffle(buffer_size=2000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "train_ds = make_dataset(\n",
        "    train_data.keys(),\n",
        "    train_data.values(),\n",
        "    training = True\n",
        ")\n",
        "test_ds = make_dataset(\n",
        "    test_data.keys(),\n",
        "    test_data.values(),\n",
        "    training = False\n",
        ")"
      ],
      "metadata": {
        "id": "q0rEPI32rEMH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_ds.take(1):\n",
        "    for image, label in zip(images, labels):\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "        print(label)"
      ],
      "metadata": {
        "id": "e-bul7yM1PyY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "4babf993-d6cc-4b4e-b187-5a1f55878402"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[   2  389  951 1065    4   61    5   16   14   10    9   11    8    3\n",
            "    0    0    0    0    0    0    0    0    0    0    0], shape=(25,), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[   2 1711   23   19   95    7   19   45    6  604 1375   39   99  366\n",
            "    3    0    0    0    0    0    0    0    0    0    0], shape=(25,), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[  2  23  34  26  56  51  57   6  28 232  83 168  71 113 114   3   0   0\n",
            "   0   0   0   0   0   0   0], shape=(25,), dtype=int64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[  2 388  77 123 814   4 495 232   5  38  10   9  11   8   3   0   0   0\n",
            "   0   0   0   0   0   0   0], shape=(25,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i = 0\n",
        "# for label in train_data.values():\n",
        "#     print(\n",
        "#         tf.strings.regex_replace(label, \"[%s]\" % re.escape(\"!\\\"#$%&'()*+,.:;=?@[\\]^_`{|}~\"), \"\")\n",
        "#     )\n",
        "#     i += 1\n",
        "#     if i == 3:\n",
        "#         break\n",
        "    "
      ],
      "metadata": {
        "id": "Ge7AbaqSjC4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorization.get_vocabulary()"
      ],
      "metadata": {
        "id": "ikaGA6DpISdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(list(json_file.values())[0])\n",
        "# vectorization(list(train_data.values()))[:3]"
      ],
      "metadata": {
        "id": "39GqXt-fkxTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.DenseNet121(\n",
        "    include_top=False,\n",
        "    input_shape=(image_height, image_width, 3),\n",
        "\n",
        ")\n",
        "# get the feature map from DenseNet\n",
        "base_model_out = base_model.output\n",
        "# squash the feature map from shape [f_height, f_width, f_channel]\n",
        "# to shape [f_height x f_width, f channel], we'll pass it through\n",
        "# a CNN Encoder later on\n",
        "base_model_out = keras.layers.Reshape(\n",
        "    (-1, base_model_out.shape[-1])\n",
        ")(base_model_out)\n",
        "\n",
        "cnn_model = keras.models.Model(\n",
        "    base_model.input,\n",
        "    base_model_out\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6bVPJQy5lcG",
        "outputId": "e6336a58-9ea2-4a64-e50b-be455c7b7c66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n",
            "29097984/29084464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Encoder(keras.Model):\n",
        "    # Since you have already extracted the features and dumped it\n",
        "    # This encoder passes those features through a Fully connected layer\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "\n",
        "        self.feature_extractor = keras.applications.DenseNet121(\n",
        "            include_top=False,\n",
        "            input_shape=(image_height, image_width, 3),\n",
        "\n",
        "        )\n",
        "        \n",
        "        self.fc = keras.layers.Dense(embedding_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        # get the feature map from DenseNet\n",
        "        x = self.feature_extractor(x)\n",
        "        # squash the feature map from shape [f_height, f_width, f_channel]\n",
        "        # to shape [f_height x f_width, f channel]\n",
        "        x = keras.layers.Reshape((-1, x.shape[-1]))(x)\n",
        "        # shape after fc == (f_height x f_width, embedding_dim)\n",
        "        x = self.fc(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "mbX4mMelNBzZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # features(CNN_encoder output) shape = (batch_size, f_height x f_width, embedding_dim)\n",
        "\n",
        "        # hidden shape == (batch_size, hidden_size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "        # print('BahdanauAttention: hidden_with_time_axis.shape == ', hidden_with_time_axis.shape)\n",
        "\n",
        "        # attention_hidden_layer shape == (batch_size, f_height x f_width, units)\n",
        "        attention_hidden_layer = tf.nn.tanh(\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis)\n",
        "        )\n",
        "\n",
        "        # score shape == (batch_size, f_height x f_width, 1)\n",
        "        # this gives an unnormalized score for each image feature\n",
        "        score = self.V(attention_hidden_layer)\n",
        "\n",
        "        # print('BahdanauAttention: score.shape == ', score.shape)\n",
        "\n",
        "        # attention_weights shape == (batch_size, f_height x f_width, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # print('BahdanauAttention: attention_weights.shape == ', attention_weights.shape)\n",
        "\n",
        "        # context vector shape after sum = (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        # print('BahdanauAttention: context_vector.shape == ', context_vector.shape)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "qhg43tIOYOzU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau vs Luong"
      ],
      "metadata": {
        "id": "yvghkvH3Ceqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Decoder(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, units, vocab_size):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.units,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True,\n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
        "        self.fc2 = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.units)\n",
        "\n",
        "    def call(self, x, features, hidden):\n",
        "        # defining attention as a separate model\n",
        "        context_vector, attention_weights = self.attention(features, hidden)\n",
        "\n",
        "        # print('RNN_Decoder: context_vector.shape == ', context_vector.shape)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        # shape == (batch_size, max_length, hidden_size)\n",
        "        x = self.fc1(output)\n",
        "\n",
        "        # x shape == (batch_size * max_length, hidden_size)\n",
        "        x = tf.reshape(x, (-1, x.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size * max_length, vocab)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x, state, attention_weights\n",
        "\n",
        "    def reset_state(self, batch_size):\n",
        "        return tf.zeros((batch_size, self.units))"
      ],
      "metadata": {
        "id": "wOpjbibZVo8U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = CNN_Encoder(embedding_dim)\n",
        "decoder = RNN_Decoder(embedding_dim, units, vectorization.vocabulary_size())"
      ],
      "metadata": {
        "id": "EQd4P-TKAbQY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none'\n",
        ")\n",
        "\n",
        "def loss_function(trues, preds):\n",
        "    loss_ = loss_object(trues, preds)\n",
        "    \n",
        "    mask = tf.cast(\n",
        "        tf.math.logical_not(tf.math.equal(trues, 0)),\n",
        "        dtype=loss_.dtype\n",
        "    )\n",
        "\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "5uYOHU4EBIuu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!mkdir checkpoints/train"
      ],
      "metadata": {
        "id": "7ecufyAFCYVI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = 'checkpoints/train'\n",
        "ckpt = tf.train.Checkpoint(\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    optimizer=optimizer\n",
        ")\n",
        "ckpt_manager = tf.train.CheckpointManager(\n",
        "    ckpt,\n",
        "    checkpoint_path,\n",
        "    max_to_keep=5\n",
        ")"
      ],
      "metadata": {
        "id": "CP6_XTeBCSyy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)"
      ],
      "metadata": {
        "id": "4ehXoIfNWUM0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=vectorization.get_vocabulary())\n",
        "index_to_word = keras.layers.StringLookup(\n",
        "    mask_token=\"\",\n",
        "    vocabulary=vectorization.get_vocabulary(),\n",
        "    invert=True)"
      ],
      "metadata": {
        "id": "Q15fA47pj1Ak"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_plot = []"
      ],
      "metadata": {
        "id": "8A1DmE6jgZUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images, targets):\n",
        "    # print('train_step: images.shape == ', images.shape)\n",
        "    loss = 0\n",
        "\n",
        "    # initializing the hidden state for each batch\n",
        "    # because the captions are not related from image to image\n",
        "    hidden = decoder.reset_state(batch_size=targets.shape[0])\n",
        "\n",
        "    dec_input = tf.expand_dims(\n",
        "        [word_to_index('<start>')] * targets.shape[0],\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        features = encoder(images)\n",
        "\n",
        "        for i in range(1, targets.shape[1]):\n",
        "            # print('train_step: dec_input.shape == ', dec_input.shape)\n",
        "            # print('train_step: features.shape == ', features.shape)\n",
        "            # print('train_step: hidden.shape == ', hidden.shape)\n",
        "            predictions, hidden, _ = decoder(dec_input, features, hidden)\n",
        "\n",
        "            loss += loss_function(targets[:, i], predictions)\n",
        "\n",
        "            dec_input = tf.expand_dims(targets[:, i], 1)\n",
        "    \n",
        "    total_loss = loss / targets.shape[1]\n",
        "\n",
        "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    return loss, total_loss"
      ],
      "metadata": {
        "id": "PnvqHwevgb3J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "id": "D_5c1mhXrr_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (images, targets) in enumerate(train_ds):\n",
        "        \n",
        "        print(targets.shape)\n",
        "        break\n",
        "\n",
        "        batch_loss, t_loss = train_step(images, targets)\n",
        "        total_loss += t_loss\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            average_batch_loss = batch_loss.numpy() / int(targets.shape[1])\n",
        "            print(f'Epoch: {epoch + 1} Batch: {batch} Loss: {average_batch_loss:.4f}')\n",
        "\n",
        "    break\n",
        "\n",
        "    loss_plot.append(total_loss / train_ds.cardinality().numpy())\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        ckpt_manager.save()\n",
        "\n",
        "    print(f'Epoch: {epoch + 1} Loss: {total_loss/train_ds.cardinality().numpy():.6f}')\n",
        "    print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlBO4L8gpmQD",
        "outputId": "0e3411c4-6e2d-4e5f-ec65-5c93882f8f37"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_plot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4XtBcVH3Wlfz",
        "outputId": "3cc0ccd0-c0e4-4fd1-cab1-8afbfdf466e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7320d04e10>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save checkpoint\n",
        "!tar -czf drive/MyDrive/checkpoint/htr/checkpoints2.tar.gz ./checkpoints"
      ],
      "metadata": {
        "id": "1FKaKZpnR9Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/checkpoint/htr/loss_plot2.pkl', 'wb') as f:\n",
        "    pickle.dump(loss_plot, f)"
      ],
      "metadata": {
        "id": "gpPEqVeOUrvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jdG1LjzT_fLj",
        "outputId": "b5756e34-40b6-49dc-9236-7344b68e7af2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract checkpoint archive\n",
        "!tar -xf drive/MyDrive/checkpoint/htr/checkpoints.tar.gz -C ./"
      ],
      "metadata": {
        "id": "IisMzO3217MD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load checkpoint\n",
        "ckpt_path = tf.train.latest_checkpoint(checkpoint_path)\n",
        "ckpt.restore(ckpt_path)"
      ],
      "metadata": {
        "id": "AIsSSyl31_Zg",
        "outputId": "91e106bb-4447-44e8-fc60-7a28fb2be794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f644c1d2550>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/checkpoint/htr/loss_plot.pkl', 'rb') as f:\n",
        "    loss_plot = pickle.load(f)"
      ],
      "metadata": {
        "id": "ZUdR-XS9VKmF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(image):\n",
        "    # image shape == (height, width, channels)\n",
        "\n",
        "    # features shape == (1, f_heigt x f_width, f_channels)\n",
        "    features = encoder(tf.expand_dims(image, axis=0))\n",
        "    attention_plot = np.zeros((seq_length, features.shape[1]))\n",
        "\n",
        "    hidden = decoder.reset_state(batch_size=1)\n",
        "\n",
        "    dec_input = tf.expand_dims([word_to_index('<start>')], axis=0)\n",
        "    result = []\n",
        "\n",
        "    for i in range(seq_length):\n",
        "        predictions, hidden, attention_weights = decoder(\n",
        "            dec_input,\n",
        "            features,\n",
        "            hidden\n",
        "        )\n",
        "\n",
        "        attention_plot[i] = tf.reshape(attention_weights, (-1,)).numpy()\n",
        "\n",
        "        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n",
        "        predicted_word = tf.compat.as_text(index_to_word(predicted_id).numpy())\n",
        "        result.append(predicted_word)\n",
        "\n",
        "        if predicted_word == '<end>':\n",
        "            return result, attention_plot\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    attention_plot = attention_plot[:len(result), :]\n",
        "    return result, attention_plot"
      ],
      "metadata": {
        "id": "IZXToNGRgQAb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, targets in train_ds:\n",
        "    for image, target in zip(images, targets):\n",
        "        # plt.figure(figsize=(15, 3))\n",
        "        # plt.imshow(1 - image)\n",
        "        # plt.show()\n",
        "        result, attention_plot = evaluate(image)\n",
        "        print(\"True:\", ' '.join([tf.compat.as_text(index_to_word(i).numpy()) for i in target if i.numpy() != 0]))\n",
        "        print('Pred:', ' '.join(result))\n",
        "    break"
      ],
      "metadata": {
        "id": "wnibACxFrAIP",
        "outputId": "2dcbf072-fc55-4161-a31c-808c0b10c110",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: <start> Số 459 phố Kim Ngưu Phường Vĩnh Tuy Quận Hai Bà Trưng Hà Nội <end>\n",
            "Pred: Số 459 phố Kim Ngưu Phường Vĩnh Tuy Quận Hai Bà Trưng Hà Nội <end>\n",
            "True: <start> Km 948600 Quốc lộ 1A Xã Điện Thắng Bắc Huyện Điện Bàn Quảng Nam <end>\n",
            "Pred: Km 948600 Quốc lộ 5A Xã Bạch Thắng Huyện Long Thành Quảng Nam <end>\n",
            "True: <start> Khu 7 Thị Trấn ái Nghĩa Huyện Đại Lộc Quảng Nam <end>\n",
            "Pred: Khu 7 Thị Trấn ái Nghĩa Huyện Đại Lộc Quảng Nam <end>\n",
            "True: <start> Số 117 Hùng Vương Phường Sở Dầu Quận Hồng Bàng Hải Phòng <end>\n",
            "Pred: Số 117 Hùng Vương Phường Sở Nghé Quận Hà Đông Hà Nội <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(image, result, attention_plot):\n",
        "\n",
        "    fig = plt.figure(figsize=(60, 12))\n",
        "\n",
        "    len_result = len(result)\n",
        "    for i in range(len_result):\n",
        "        temp_att = np.resize(attention_plot[i], (3, 59))\n",
        "        grid_size = max(int(np.ceil(len_result/2)), 2)\n",
        "        ax = fig.add_subplot(grid_size, grid_size, i+1)\n",
        "        ax.set_title(result[i])\n",
        "        img = ax.imshow(1 - image / tf.reduce_max(image))\n",
        "        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "iStYjWRGqrzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, targets in train_ds:\n",
        "    for image, target in zip(images, targets):\n",
        "        result, attention_plot = evaluate(image)\n",
        "        plot_attention(image, result, attention_plot)\n",
        "        print(\"True:\", ' '.join([tf.compat.as_text(index_to_word(i).numpy()) for i in target if i.numpy() != 0]))\n",
        "        print('Pred:', ' '.join(result))\n",
        "    break"
      ],
      "metadata": {
        "id": "F667KQru8Glf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(images, targets):\n",
        "    # images shape == (batch_size, height, width, channels)\n",
        "\n",
        "    # features shape == (batch_size, f_heigt x f_width, f_channels)\n",
        "    features = encoder(images)\n",
        "\n",
        "    hidden = decoder.reset_state(batch_size=targets.shape[0])\n",
        "\n",
        "    results = tf.expand_dims([word_to_index('<start>')] * targets.shape[0], axis=1)\n",
        "\n",
        "    for i in range(seq_length):\n",
        "        predictions, hidden, attention_weights = decoder(\n",
        "            results[..., -1:], #(4, 1)\n",
        "            features,\n",
        "            hidden\n",
        "        )\n",
        "\n",
        "        predicted_id = tf.expand_dims(\n",
        "            tf.argmax(predictions, axis=-1),\n",
        "            axis=-1\n",
        "        )\n",
        "\n",
        "        results = tf.concat([results, predicted_id], axis=-1) # tf.expand_dims(predicted_id, 0)\n",
        "        \n",
        "        # print(results.shape)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "for images, targets in train_ds:\n",
        "    results = evaluate(images, targets)\n",
        "    true_texts = [' '.join([tf.compat.as_text(index_to_word(i).numpy()) for i in j[1:-1] if i.numpy() != 0 or i != word_to_index('<end>')])\n",
        "        for j in targets]\n",
        "    pred_texts = [' '.join([tf.compat.as_text(index_to_word(i).numpy()) for i in j[1:] if i != word_to_index('<end>')])\n",
        "        for j in results]\n",
        "    \n",
        "    print(wer(true_texts, pred_texts))\n",
        "        \n",
        "    break\n"
      ],
      "metadata": {
        "id": "UDzvg-qfvpfV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb69fe1-431a-4058-cd03-cdca6a36ceef"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(true_texts)\n",
        "print(pred_texts)"
      ],
      "metadata": {
        "id": "03UDv5Tj9zkn",
        "outputId": "7434e461-fa73-48fe-c746-b8ad27b00bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Thôn Đoài xã Liên Hà Xã Liên Hà Huyện Đan Phượng Hà Nội <end>', 'Số 106 phố Văn La Phường Phú La Quận Hà Đông Hà Nội <end>', 'Xóm yên Thịnh Xã Nghi Xuân Huyện Nghi Lộc Nghệ An <end>', '115 Nguyễn Huệ Quận 1 TP Hồ Chí Minh <end>']\n",
            "['Thôn Đoài xã Liên Hà Xã Liên Hà Huyện Đan Phượng Hà Nội', 'Số 106 phố Văn La Phường Phú La Quận Hà Đông Hà Nội', 'Xóm yên Thịnh Xã Nghi Xuân Huyện Nghi Lộc Nghệ An', '115 Nguyễn Huệ Quận 1 TP Hồ Chí Minh']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHE_B0Xx7VWl",
        "outputId": "94fadb78-9d4e-41f1-9605-d8949ce0b73f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149858 sha256=b42e4f8517f64c02bbbacef2d5d1d10697633f4638576d554894938c6b9336e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import wer"
      ],
      "metadata": {
        "id": "cY2fAEUH9bAb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, target in zip(images, targets):\n",
        "    result, attention_plot = evaluate(image)\n",
        "    print(\"True:\", ' '.join([tf.compat.as_text(index_to_word(i).numpy()) for i in target if i.numpy() != 0]))\n",
        "    print('Pred:', ' '.join(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYUai8Kn8OSX",
        "outputId": "9120a674-fe0d-44d9-c137-7faa291d17c6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True: <start> Khu 3 Xã Cát Quế Huyện Hoài Đức Hà Nội <end>\n",
            "Pred: Khu 3 Xã Cát Quế Huyện Hoài Đức Hà Nội <end>\n",
            "True: <start> Số 79 Đường số 37 Khu phố 2 Phường 10 Quận 6 TP Hồ Chí Minh <end>\n",
            "Pred: Số 79 Đường số 37 Khu phố 2 Phường 10 Quận 6 TP Hồ Chí Minh <end>\n",
            "True: <start> Số 25 Nguyễn Bỉnh Khiêm Phường 8 Thành phố Cà Mau Cà Mau <end>\n",
            "Pred: Số 25 Nguyễn Bỉnh Khiêm Phường 8 Thành phố Cà Mau Cà Mau <end>\n",
            "True: <start> 271/7B An Dương Vương Phường 03 Quận 5 TP Hồ Chí Minh <end>\n",
            "Pred: 271/7B An Dương Vương Phường 03 Quận 5 TP Hồ Chí Minh <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "\n",
        "https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "\n",
        "https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/image_captioning.ipynb#scrollTo=StQK3dgDcri0\n",
        "\n",
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/\n",
        "\n",
        "https://keras.io/examples/nlp/semantic_similarity_with_bert/\n"
      ],
      "metadata": {
        "id": "Z5CJxAyXC_KR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "1. https://arxiv.org/pdf/1703.09137.pdf\n",
        "2. https://viblo.asia/p/a-guide-to-image-captioning-part-1-gioi-thieu-bai-toan-sinh-mo-ta-cho-anh-gAm5yr88Kdb\n",
        "3. https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "4. https://arxiv.org/pdf/1502.03044.pdf\n",
        "5. https://keras.io/examples/vision/image_captioning/\n",
        "6. https://machinelearningmastery.com/the-bahdanau-attention-mechanism/\n",
        "7. https://keras.io/examples/audio/ctc_asr/"
      ],
      "metadata": {
        "id": "wMh5GUVjinie"
      }
    }
  ]
}