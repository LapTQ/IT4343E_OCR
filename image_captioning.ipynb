{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_captioning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsAjIgSdjmcTq2nsEYMIpU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LapTQ/image_captioning/blob/main/image_captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hungpham13/Vietnamese-HTR.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ_6PnrTXw-c",
        "outputId": "0a364cd9-fd22-43b0-a0bb-eaf4ef0eabad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Vietnamese-HTR'...\n",
            "remote: Enumerating objects: 2403, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 2403 (delta 0), reused 4 (delta 0), pack-reused 2399\u001b[K\n",
            "Receiving objects: 100% (2403/2403), 427.59 MiB | 42.71 MiB/s, done.\n",
            "Checking out files: 100% (2395/2395), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rQiOo4_Fd7lh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from pathlib import Path\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -20 '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/0825_DataSamples 1/labels.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgkwHIEfYniD",
        "outputId": "5e59621a-b58d-48fd-a94c-e182c58367cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"1.jpg\": \"Số 3 Nguyễn Ngọc Vũ, Hà Nội\",\n",
            "    \"2.jpg\": \"Số 30 Nguyên Hồng, Láng Hạ, Đống Đa, Hà Nội\",\n",
            "    \"3.jpg\": \"58 Thái Thịnh, Đống Đa, Hà Nội\",\n",
            "    \"4.jpeg\": \"Số 370/8 khu phố 5B, phường Tân Biên, Biên Hòa, Đồng Nai\",\n",
            "    \"5.jpg\": \"Vĩnh Trung Plaza, B, 255-257 đường Hùng Vương, phường Vĩnh Trung\",\n",
            "    \"6.jpg\": \"Tòa nhà 34T, Hoàng Đạo Thúy, Hà Nội\",\n",
            "    \"7.jpg\": \"40 Cát Linh, Đống Đa, Hà Nội\",\n",
            "    \"8.jpg\": \"phòng 101, tầng 1, lô 04-TT5B, khu đô thị Tây Nam Linh Đàm\",\n",
            "    \"9.JPG\": \"Nhà 87 ngõ 416 Đê La Thành\",\n",
            "    \"10.JPG\": \"Up coworking Space, 89 Láng Hạ, Hà Nội\",\n",
            "    \"11.jpg\": \"192 Ngô Đức Kế, quận 1, Hồ Chí Minh\",\n",
            "    \"12.jpg\": \"số 5 Công Trường Mê Linh, phường Bến Nghé, quận 1\",\n",
            "    \"13.jpg\": \"90A đường Mai Xuân Thưởng, tỉnh Gia Lai\",\n",
            "    \"14.jpg\": \"96/7/12B Phạm Văn Đồng, thành phố Pleiku\",\n",
            "    \"15.jpg\": \"168 Ngô Gia Tự, thành phố Hà Tĩnh\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir = '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/0916_Data Samples 2'\n",
        "test_img_dir = '/content/Vietnamese-HTR/Data 1: Handwriting OCR for Vietnamese Address/1015_Private Test'\n",
        "\n",
        "image_height, image_width = 120, 1900\n",
        "vocab_size = 10000\n",
        "seq_length = 25\n",
        "embed_dim = 512\n",
        "ff_dim = 512\n",
        "\n",
        "batch_size = 54\n",
        "epochs = 30\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "mjm7Y-lYdZYT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of training images:', len(list(Path(train_img_dir).glob('*.png'))))\n",
        "print('Number of testing images:', len(list(Path(test_img_dir).glob('*.png'))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU8HNz-regz_",
        "outputId": "12606bba-5b76-4f2b-d8a8-125044089b55"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 1823\n",
            "Number of testing images: 549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "train_json = json.load(\n",
        "    open(train_img_dir + '/labels.json', 'r')\n",
        ")\n",
        "\n",
        "test_json = json.load(\n",
        "    open(test_img_dir + '/labels.json', 'r')\n",
        ")"
      ],
      "metadata": {
        "id": "pQGy_mYAayjJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max([len(label.split()) for label in json_file.values()])\n",
        "# tokens = set()\n",
        "# for label in json_file.values():\n",
        "#     for token in label.split():\n",
        "#         tokens.add(token)\n",
        "# len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMNBoqXifjvV",
        "outputId": "8a9b566f-58f8-45cf-bf44-bd8cab7a36b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2494"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_and_resize(img_path):\n",
        "    img_string = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img_string)\n",
        "\n",
        "    # resize to desired shape\n",
        "    img = tf.image.resize_with_pad(img, image_height, image_width)\n",
        "\n",
        "    # This will convert to float values in [0, 1]\n",
        "    # img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    return img\n",
        "\n",
        "vectorization = keras.layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=seq_length,\n",
        "    standardize=lambda label: tf.strings.regex_replace(label, \"[%s]\" % re.escape(\"!\\\"#$%&'()*+,.:;<=>?@[\\]^_`{|}~\"), \"\")\n",
        ")\n",
        "\n",
        "vectorization.adapt(list(train_json.values()))\n",
        "\n",
        "def preprocess_input(img_path, label):\n",
        "    return decode_and_resize(img_path), vectorization(label)\n",
        "\n",
        "def make_dataset(img_paths, labels, training):\n",
        "    assert training is True or training is False\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, labels))\n",
        "    dataset = dataset.map(preprocess_input, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.prefetch(buffer_size=2000)\n",
        "    dataset = dataset.cache()\n",
        "    if training: \n",
        "        dataset = dataset.shuffle(buffer_size=2000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(\n",
        "    [str(path) for path in sorted(list(Path(train_img_dir).glob('*.png')))],\n",
        "    train_json.values(),\n",
        "    training = True\n",
        ")\n",
        "test_ds = make_dataset(\n",
        "    [str(path) for path in sorted(list(Path(test_img_dir).glob('*.png')))],\n",
        "    test_json.values(),\n",
        "    training = False\n",
        ")"
      ],
      "metadata": {
        "id": "q0rEPI32rEMH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for label in json_file.values():\n",
        "#     print(\n",
        "#         tf.strings.regex_replace(label, \"[%s]\" % re.escape(\"!\\\"#$%&'()*+,.:;<=>?@[\\]^_`{|}~\"), \"\")\n",
        "#     )"
      ],
      "metadata": {
        "id": "Ge7AbaqSjC4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(json_file.values())[0])\n",
        "vectorization(list(json_file.values())[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39GqXt-fkxTd",
        "outputId": "2ee990cf-2a38-4986-9ad9-6dc70863ac50"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số 253 đường Trần Phú, Thị trấn Nam Sách, Huyện Nam Sách, Hải Dương\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=int64, numpy=\n",
              "array([ 11, 875,  46,  75,  20,  18,  39,  37, 369,   4,  37, 369,  32,\n",
              "        52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "1. https://arxiv.org/pdf/1703.09137.pdf\n",
        "2. https://viblo.asia/p/a-guide-to-image-captioning-part-1-gioi-thieu-bai-toan-sinh-mo-ta-cho-anh-gAm5yr88Kdb\n",
        "3. https://www.tensorflow.org/tutorials/text/image_captioning\n",
        "4. https://arxiv.org/pdf/1502.03044.pdf\n",
        "5. https://keras.io/examples/vision/image_captioning/\n"
      ],
      "metadata": {
        "id": "wMh5GUVjinie"
      }
    }
  ]
}